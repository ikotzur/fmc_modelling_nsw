{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on dataframe of locations, retrieve Sentinel reflectance via DEA datacube and calculate FMC timeseries then save just result back to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in DEA Sandbox or the DEA environment on NCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('dea-notebooks/Scripts/') # i.e. dea-notebooks/Scripts/\n",
    "import datacube\n",
    "from dea_datahandling import load_ard\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "dc = datacube.Datacube(app='sentinel_fmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to data in workign directory\n",
    "gpath = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates of locations to model FMC timeseries\n",
    "gdf = gpd.read_file(gpath+'coords_select.csv')\n",
    "gdf[['x','y']] = gdf[['x','y']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Look Up Table from file\n",
    "lut = np.load(gpath+'lut_filtered.npy')\n",
    "# the squares of the LUT\n",
    "squares = np.einsum(\"ij,ij->i\", lut[:, 1:], lut[:, 1:]) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defin reflectance bands to retrieve from datacube\n",
    "measurements=['nbart_blue','nbart_green','nbart_red',\n",
    "             'nbart_red_edge_1','nbart_red_edge_2','nbart_red_edge_3',\n",
    "             'nbart_nir_1','nbart_nir_2','nbart_swir_2','nbart_swir_3']\n",
    "\n",
    "# number of LUT values to consider in retrieval (optimised to 30)\n",
    "top_n = 30\n",
    "\n",
    "# Df to save results\n",
    "pd.DataFrame(columns=['time', 'x', 'y', 'fmc', 'index', 'spatial_ref']).to_csv(gpath+'fmc_sites.csv')\n",
    "\n",
    "# Define inputs for retrieval algorithym \n",
    "inputs = ['nbart_green','nbart_red','nbart_red_edge_1','nbart_red_edge_2','nbart_red_edge_3',\n",
    "             'nbart_nir_1','nbart_nir_2','nbart_swir_2','nbart_swir_3','ndii']\n",
    "\n",
    "# Loop over gdf of locations extracting timeseries datacube\n",
    "for site in gdf.itertuples(): #TODO\n",
    "    start = time.time()\n",
    "    print(site.Index, site.y, site.x)\n",
    "    \n",
    "    # Query the datacube\n",
    "    try:\n",
    "        s2_cube = load_ard(dc=dc, products=['s2a_ard_granule','s2b_ard_granule'], crs='EPSG:3577',\n",
    "                 x=(site.x-10,site.x+10), y=(site.y+10,site.y-10), time=('2015-01-01','2022-12-31'),#TODO\n",
    "                   measurements=measurements, output_crs='EPSG:3577', resolution=(-20, 20),\n",
    "                   mask_pixel_quality=True, group_by='solar_day')\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    # Start FMC model\n",
    "    s2_cube['ndii'] = ((s2_cube.nbart_nir_1-s2_cube.nbart_swir_2)/(s2_cube.nbart_nir_1+s2_cube.nbart_swir_2))\n",
    "    s2_cube = s2_cube / 10000\n",
    "    s2_cube['ndvi'] = ((s2_cube.nbart_nir_1-s2_cube.nbart_red)/(s2_cube.nbart_nir_1+s2_cube.nbart_red)) \n",
    "    \n",
    "    # Create output array frame\n",
    "    canvas = np.ones(s2_cube['ndvi'].values.shape, dtype=np.float32) * np.nan\n",
    "    \n",
    "    # Loop over pixels and time, retrieve FMC from LUT\n",
    "    for t in range(s2_cube['ndvi'].values.shape[0]):\n",
    "\n",
    "        for j in range(s2_cube['ndvi'].values.shape[1]):\n",
    "\n",
    "            for i in range(s2_cube['ndvi'].values.shape[2]):\n",
    "                x = s2_cube[inputs].to_array().values[:,t, j, i]\n",
    "                if np.isnan(s2_cube['ndvi'][t, j, i]) or s2_cube['ndvi'][t, j, i] < 0.15:\n",
    "                    continue\n",
    "\n",
    "                θ = -1 * (\n",
    "                    np.einsum(\"ij,j->i\", lut[:, 1:], x)\n",
    "                    / (np.einsum(\"i,i->\", x, x) ** 0.5 * squares)\n",
    "                )\n",
    "\n",
    "                idxs = np.argpartition(θ, top_n)[:top_n] # find a number of closely matching spectra\n",
    "                canvas[t, j, i] = np.median(lut[idxs, 0]) # takes median FMC of best matching spectra\n",
    "    \n",
    "    # Make new dataarray with same coordinates as input data\n",
    "    s2_cube['fmc'] = (['time','y','x'], canvas)\n",
    "    # Write to file by appending to fmc_sites.csv\n",
    "    s2_cube[['fmc','index']].to_dataframe().reset_index().to_csv(\n",
    "        gpath+'fmc_sites_filtered.csv',mode='a',header=False)\n",
    "    \n",
    "    print(time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
